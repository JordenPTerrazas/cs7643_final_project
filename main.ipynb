{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import argparse\n",
    "import time\n",
    "import copy\n",
    "import unittest\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics.audio.pesq import PerceptualEvaluationSpeechQuality\n",
    "from torchmetrics.audio.stoi import ShortTimeObjectiveIntelligibility\n",
    "import torchaudio.transforms as transforms\n",
    "import torchaudio.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from transforms.not_our_stdct import sdct_torch, isdct_torch\n",
    "from modules import MFNet, MFNetAct\n",
    "from losses import TotalLoss\n",
    "from dataloader import DNSDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  config = \"configs/config.yaml\"\n",
    "\n",
    "args=Args()\n",
    "\n",
    "window_eps = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "global args\n",
    "with open(args.config) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "for key in config:\n",
    "    for k, v in config[key].items():\n",
    "        setattr(args, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def PESQ(output, target, mode = 'wb'):\n",
    "    \"\"\"\n",
    "    Calculates the Perceptual Evaluation of Speech Quality metric.\n",
    "    \n",
    "    PESQ is recognized industry standard for audio quality that takes into considerations characteristics such as: \n",
    "    audio sharpness, call volume, background noise, clipping, audio interference etc. \n",
    "    PESQ returns a score between -0.5 and 4.5 with the higher scores indicating a better quality.\n",
    "    \n",
    "    This implementation uses the torchmetrics library from Lightning AI described here: \n",
    "    https://lightning.ai/docs/torchmetrics/stable/audio/perceptual_evaluation_speech_quality.html\n",
    "    \"\"\"\n",
    "    if mode == 'nb':\n",
    "        fs = 8000\n",
    "    elif mode == 'wb':\n",
    "        fs = 16000\n",
    "    pesq = PerceptualEvaluationSpeechQuality(fs, 'wb')\n",
    "\n",
    "    try:\n",
    "        out = pesq(output, target)\n",
    "    except:\n",
    "        print(\"Error in PESQ\")\n",
    "        out = torch.tensor(-0.5)\n",
    "    return out\n",
    "\n",
    "\n",
    "def STOI(output, target):\n",
    "    \"\"\"\n",
    "    Calculate Short-Time Objective Intelligibility metric for evaluating speech signals.\n",
    "    \n",
    "    STOI is highly correlated with the intelligibility of degraded speech signals.\n",
    "    \n",
    "    This implementation uses the torchmetrics library from Lightning AI described here: \n",
    "    https://lightning.ai/docs/torchmetrics/stable/audio/short_time_objective_intelligibility.html\n",
    "    \"\"\"\n",
    "    stoi = ShortTimeObjectiveIntelligibility(16000, False)\n",
    "    return stoi(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, data_loader, model, optimizer, criterion, writer, scheduler):\n",
    "    iter_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    pesq = AverageMeter()\n",
    "    stoi = AverageMeter()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.to(\"cuda\")\n",
    "   \n",
    "    for idx, (input_waveforms, target_waveforms) in enumerate(data_loader):\n",
    "        start = time.time()\n",
    "        \n",
    "        # FOR TESTING PURPOSES\n",
    "        # TO VERIFY THAT MODEL IS LEARNING\n",
    "        # target, sample_rate = torchaudio.load(\"./data/datasets/DNS_subset_10/clean/clean_fileid_0.wav\")\n",
    "        # data, sample_rate = torchaudio.load(\"./data/datasets/DNS_subset_10/noisy/book_11284_chp_0013_reader_05262_6_59oHl43FnXw_snr8_fileid_0.wav\")\n",
    "        # data, target = data[None,:,:], target[None,:,:]\n",
    "        # print(data.shape, target.shape)\n",
    "        # # # # # # # # # # # #\n",
    "        # # # # # # # # # # # #\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            input_waveforms = input_waveforms.cuda()\n",
    "            target_waveforms = target_waveforms.cuda()\n",
    "        \n",
    "        # Fwd pass \n",
    "        out = model.forward(input_waveforms)\n",
    "        \n",
    "        # Remove padding (9 comes from 16 - 999 % 16, e.g. we can code to be dynamic later)\n",
    "        out = out[:,:,:,:-9]\n",
    "        \n",
    "        # Compute loss then backwards\n",
    "        loss = criterion(out, target_waveforms)\n",
    "        print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Before the step, log gradients\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram(name + '/grad', param.grad, epoch * len(data_loader) + idx)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Inverse Transform\n",
    "        i_out = isdct_torch(out, frame_step=160, frame_length=320, window=torch.sqrt(torch.hann_window(window_length=320)).cuda() + window_eps) \n",
    "        i_target = isdct_torch(target_waveforms, frame_step=160, frame_length=320, window=torch.sqrt(torch.hann_window(window_length=320)).cuda() + window_eps)\n",
    "        \n",
    "        # Clean up large values from Inverse Transform\n",
    "        i_target = torch.nan_to_num(i_target, nan=0.0, posinf=40.0, neginf=-40.0)\n",
    "        i_out = torch.nan_to_num(i_out, nan=0.0, posinf=40.0, neginf=-40.0)\n",
    "        print(\"Max in target\", torch.max(i_target))\n",
    "        print(\"Max in out\", torch.max(i_out))\n",
    "\n",
    "        # Compute PESQ & STOI \n",
    "        batch_pesq = PESQ(i_out, i_target)\n",
    "        batch_stoi = STOI(i_out, i_target)\n",
    "\n",
    "        # Update Everything\n",
    "        batch_size = out.shape[0]\n",
    "        losses.update(loss.item(), out.shape[0])\n",
    "        pesq.update(batch_pesq, batch_size)\n",
    "        stoi.update(batch_stoi, batch_size)\n",
    "        iter_time.update(time.time() - start)\n",
    "\n",
    "        if idx % args.save_every == 0:\n",
    "            save_dir = args.save_dir + '/checkpoints'\n",
    "            if os.path.exists(save_dir):\n",
    "                torch.save(model.state_dict(), save_dir + '/' + args.model + f'_epoch{epoch}' + f'_step{idx}' + '.pth')\n",
    "                torch.save(optimizer.state_dict(), save_dir + '/' + 'optim' + f'_epoch{epoch}' + f'_step{idx}' + '_optimizer.pth')\n",
    "                torch.save(scheduler.state_dict(), save_dir + '/' + 'scheduler' + f'_epoch{epoch}' + f'_step{idx}' + '_scheduler.pth')\n",
    "            else:\n",
    "                os.makedirs(save_dir)\n",
    "                torch.save(model.state_dict(), save_dir + '/' + args.model + f'_epoch{epoch}' + f'_step{idx}' + '.pth')\n",
    "                torch.save(optimizer.state_dict(), save_dir + '/' + 'optim' + f'_epoch{epoch}' + f'_step{idx}' + '_optimizer.pth')\n",
    "                torch.save(scheduler.state_dict(), save_dir + '/' + 'scheduler' + f'_epoch{epoch}' + f'_step{idx}' + '_scheduler.pth')\n",
    "        \n",
    "        if idx % 10 == 0:\n",
    "            writer.add_scalar('Loss/train', loss.item(), epoch * len(data_loader) + idx)\n",
    "            writer.add_scalar('PESQ/train', batch_pesq, epoch * len(data_loader) + idx)\n",
    "            writer.add_scalar('STOI/train', batch_stoi, epoch * len(data_loader) + idx)\n",
    "            print(('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                   'Time {iter_time.val:.3f} ({iter_time.avg:.3f})\\t'\n",
    "                   'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                   'PESQ {pesq.val:.4f} ({pesq.avg:.4f})\\t'\n",
    "                   'STOI {stoi.val:.4f} ({stoi.avg:.4f})\\t').format(\n",
    "                       epoch,\n",
    "                       idx,\n",
    "                       len(data_loader),\n",
    "                       iter_time=iter_time,\n",
    "                       loss=losses,\n",
    "                       pesq=pesq,\n",
    "                       stoi=stoi))\n",
    "\n",
    "\n",
    "def validate(epoch, val_loader, model, criterion, writer):\n",
    "    iter_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    pesq = AverageMeter()\n",
    "    stoi = AverageMeter()\n",
    "\n",
    "    for idx, (data, target) in enumerate(val_loader):\n",
    "        start = time.time()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            out = out[:,:,:,:-9]\n",
    "            loss = criterion(out, target)\n",
    "\n",
    "        i_out = isdct_torch(out, frame_step=160, frame_length=320, window=torch.sqrt(torch.hann_window(window_length=320)).cuda() + window_eps)\n",
    "        i_target = isdct_torch(target, frame_step=160, frame_length=320, window=torch.sqrt(torch.hann_window(window_length=320)).cuda() + window_eps)\n",
    "        \n",
    "        # Clean up large values from Inverse Transform\n",
    "        i_target = torch.nan_to_num(i_target, nan=0.0, posinf=40.0, neginf=-40.0)\n",
    "        i_out = torch.nan_to_num(i_out, nan=0.0, posinf=40.0, neginf=-40.0)\n",
    "        \n",
    "        batch_pesq = PESQ(i_out, i_target)\n",
    "        batch_stoi = STOI(i_out, i_target)\n",
    "        \n",
    "        batch_size = out.shape[0]\n",
    "        losses.update(loss.item(), out.shape[0])\n",
    "        pesq.update(batch_pesq, batch_size)\n",
    "        stoi.update(batch_stoi, batch_size)\n",
    "        iter_time.update(time.time() - start)\n",
    "        \n",
    "        if idx % 10 == 0:\n",
    "            writer.add_scalar('Loss/val', loss.item(), epoch * len(val_loader) + idx)\n",
    "            writer.add_scalar('PESQ/val', batch_pesq, epoch * len(val_loader) + idx)\n",
    "            writer.add_scalar('STOI/val', batch_stoi, epoch * len(val_loader) + idx)\n",
    "            print(('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                   'Time {iter_time.val:.3f} ({iter_time.avg:.3f})\\t'\n",
    "                   'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                   'PESQ {pesq.val:.4f} ({pesq.avg:.4f})\\t'\n",
    "                   'STOI {stoi.val:.4f} ({stoi.avg:.4f})\\t').format(\n",
    "                       epoch,\n",
    "                       idx,\n",
    "                       len(val_loader),\n",
    "                       iter_time=iter_time,\n",
    "                       loss=losses,\n",
    "                       pesq=pesq,\n",
    "                       stoi=stoi))\n",
    "\n",
    "    print(('* PESQ: {pesq.avg:.4f}\\t* STOI: {stoi.avg:.4f}\\t').format(pesq=pesq, stoi=stoi))\n",
    "    return pesq.avg, stoi.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # waveform, sample_rate = torchaudio.load(\"data/datasets/blind_test_set/noreverb_fileid_0.wav\")\n",
    "    # stdct_waveform = sdct_torch(waveform, 320, 160, torch.hann_window)\n",
    "    \n",
    "    global args\n",
    "    args = parser.parse_args()\n",
    "    with open(args.config) as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    for key in config:\n",
    "        for k, v in config[key].items():\n",
    "            setattr(args, k, v)\n",
    "\n",
    "    # train_dataset = torchaudio.datasets.LIBRISPEECH(\n",
    "    #     root = \"./data/datasets/LIBRISPEECH\",\n",
    "    #     url = \"dev-clean\",\n",
    "    #     download = True\n",
    "    # )\n",
    "    # train_loader = DataLoader(\n",
    "    #     train_dataset, \n",
    "    #     batch_size=args.batch_size, \n",
    "    #     shuffle=True\n",
    "    # )\n",
    "    # test_dataset = None\n",
    "    # test_loader = None\n",
    "    train_dataset = DNSDataset(\n",
    "        clean_dir=args.train_label_dir,\n",
    "        noisy_dir=args.train_data_dir,\n",
    "        transform=sdct_torch,\n",
    "        transform_kwargs={\"frame_length\": 320, \"frame_step\": 160, \"window\": torch.sqrt(torch.hann_window(window_length=320)) + window_eps}\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_dataset = DNSDataset(\n",
    "        clean_dir=args.val_label_dir,\n",
    "        noisy_dir=args.val_data_dir,\n",
    "        transform=sdct_torch,\n",
    "        transform_kwargs={\"frame_length\": 320, \"frame_step\": 160, \"window\": torch.sqrt(torch.hann_window(window_length=320)) + window_eps}\n",
    "    )\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Hyper-Parameters: gamma, lr, betas, weight_decay, epochs\n",
    "    start_epoch = 0\n",
    "    if args.model == \"MFNet\":\n",
    "        model = MFNet(in_channels = 1, out_channels = 16)\n",
    "\n",
    "        if args.load_checkpoint:\n",
    "            model.load_state_dict(torch.load(args.checkpoint_model_path))\n",
    "            start_epoch = args.start_epoch\n",
    "        else:\n",
    "            start_epoch = 0\n",
    "    elif args.model == \"MFNetAct\":\n",
    "        model = MFNetAct(in_channels = 1, out_channels = 16)\n",
    "        \n",
    "        if args.load_checkpoint:\n",
    "            model.load_state_dict(torch.load(args.checkpoint_model_path))\n",
    "            start_epoch = args.start_epoch\n",
    "        else:\n",
    "            start_epoch = 0\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    criterion = TotalLoss(gamma = 0.5)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr = args.lr,\n",
    "        betas = args.betas,\n",
    "        weight_decay = args.weight_decay\n",
    "    )\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=args.anneal_epochs, eta_min=0.0001)\n",
    "\n",
    "    if args.load_checkpoint:\n",
    "        optimizer.load_state_dict(torch.load(args.checkpoint_optimizer_path))\n",
    "        scheduler.load_state_dict(torch.load(args.checkpoint_scheduler_path))\n",
    "    \n",
    "    if os.path.exists(args.save_dir + '/logs'):\n",
    "        writer = SummaryWriter(args.save_dir + '/logs')\n",
    "    else:\n",
    "        os.makedirs(args.save_dir + '/logs')\n",
    "        writer = SummaryWriter(args.save_dir + '/logs')\n",
    "\n",
    "    best_pesq = 0.0\n",
    "    best_stoi = 0.0\n",
    "    best_model = None\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        # train loop\n",
    "        train(epoch, train_dataloader, model, optimizer, criterion, writer, scheduler)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # validation loop\n",
    "        pesq, stoi = validate(epoch, val_dataloader, model, criterion, writer)\n",
    "\n",
    "        if pesq > best_pesq and stoi > best_stoi:\n",
    "            best_pesq = pesq\n",
    "            best_stoi = stoi\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "            if args.save_best:\n",
    "                best_save_dir = args.save_dir + '/best'\n",
    "                if os.path.exists(best_save_dir):\n",
    "                    torch.save(best_model.state_dict(), best_save_dir + '/' + args.model + '.pth')\n",
    "                else:\n",
    "                    os.makedirs(best_save_dir)\n",
    "                    torch.save(best_model.state_dict(), best_save_dir + '/' + args.model + '.pth')\n",
    "\n",
    "            print('Best Prec @1 PESQ: {:.4f}'.format(best_pesq))\n",
    "            print('Best Prec @1 STOI: {:.4f}'.format(best_stoi))\n",
    "\n",
    "    writer.close()\n",
    "    \n",
    "class TestMain(unittest.TestCase):\n",
    "    def test_mfnet(self):\n",
    "        train_dataset = torchaudio.datasets.LIBRISPEECH(\n",
    "            root = \"./data/datasets/LIBRISPEECH\",\n",
    "            url = \"dev-clean\",\n",
    "            download = True\n",
    "        )\n",
    "        \n",
    "        # Load the data\n",
    "        waveform, sample_rate = torchaudio.load(\"./data/datasets/blind_test_set/noreverb_fileid_0.wav\")\n",
    "        noise, _ = torchaudio.load(\"./data/datasets/blind_test_set/noreverb_fileid_1.wav\")\n",
    "        snr_dbs = torch.tensor([20, 10, 3])\n",
    "        noisy_speeches = F.add_noise(waveform, noise, snr_dbs)\n",
    "        print(waveform.shape, sample_rate)\n",
    "        print(noisy_speeches.shape)\n",
    "\n",
    "        self.assertTrue(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
